{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ab045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUG: Columns BEFORE rename ---\n",
      "['category', 'rating', 'label', 'text_']\n",
      "\n",
      "--- DEBUG: Columns AFTER rename ---\n",
      "['category', 'rating', 'label', 'text']\n",
      "Data Preprocessing Complete.\n",
      "Model Training Complete.\n",
      "\n",
      "Model Accuracy: 86.29%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Genuine (0)       0.87      0.86      0.86      4044\n",
      "    Fake (1)       0.86      0.87      0.86      4043\n",
      "\n",
      "    accuracy                           0.86      8087\n",
      "   macro avg       0.86      0.86      0.86      8087\n",
      "weighted avg       0.86      0.86      0.86      8087\n",
      "\n",
      "\n",
      "Model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# --- 1. Data Loading & Preprocessing ---\n",
    "\n",
    "# Download NLTK resources (stopwords)\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Cleans and prepares a single review text.\"\"\"\n",
    "    # Check if text is a string\n",
    "    if not isinstance(text, str):\n",
    "        return \"\" # Return empty string for non-string (e.g., float, int) inputs\n",
    "        \n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)  # Keep only letters\n",
    "    text = text.lower()                     # Convert to lowercase\n",
    "    words = text.split()                    # Split into words\n",
    "    # Stem and remove stopwords\n",
    "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# --- IMPORTANT: Load your *real* dataset here ---\n",
    "# Make sure your CSV file is named 'reviews.csv' and is in the same folder\n",
    "try:\n",
    "    # Try to read the CSV with a common encoding error handler\n",
    "    df = pd.read_csv('reviews.csv', encoding='utf-8', encoding_errors='ignore')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'reviews.csv' not found. Make sure it's in the same folder as train_model.py\")\n",
    "    exit()\n",
    "\n",
    "# --- DEBUGGING STEP 1 ---\n",
    "# Print the columns *exactly* as pandas sees them *before* the rename\n",
    "print(\"\\n--- DEBUG: Columns BEFORE rename ---\")\n",
    "print(list(df.columns))\n",
    "\n",
    "# --- FIX FOR THE KAGGLE DATASET ---\n",
    "# The dataset from the link has a text column named 'text_' and a label column named 'label'\n",
    "df = df.rename(columns={'text_': 'text', 'label': 'label'})\n",
    "\n",
    "print(\"\\n--- DEBUG: Columns AFTER rename ---\")\n",
    "print(list(df.columns))\n",
    "# ------------------------\n",
    "\n",
    "# Check if the 'text' or 'label' columns exist after renaming\n",
    "if 'text' not in df.columns or 'label' not in df.columns:\n",
    "    print(\"\\n--- ERROR ---\")\n",
    "    print(\"The 'text' or 'label' column was not found.\")\n",
    "    print(\"Please check the 'df.rename' line in the code and make sure\")\n",
    "    print(\"you have replaced the placeholders with your *real* CSV column names.\")\n",
    "    print(\"\\nAvailable columns in your CSV are:\")\n",
    "    print(list(df.columns))\n",
    "    exit()\n",
    "\n",
    "# Apply preprocessing to your text column\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"Data Preprocessing Complete.\")\n",
    "\n",
    "# --- 2. Feature Engineering (TF-IDF) ---\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "y = df['label']\n",
    "\n",
    "# --- 3. Model Training (IMPROVED) ---\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We add stratify=y to keep the same percentage of fake/genuine in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y) # <-- IMPROVEMENT 1\n",
    "\n",
    "# Initialize and train the classifier\n",
    "# We add class_weight='balanced' to help the model learn from unbalanced data\n",
    "model = LogisticRegression(class_weight='balanced') # <-- IMPROVEMENT 2\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model Training Complete.\")\n",
    "\n",
    "# --- 4. Model Evaluation ---\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"\\nModel Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# Added zero_division_handling for cases where a class has no predictions\n",
    "print(classification_report(y_test, y_pred, target_names=['Genuine (0)', 'Fake (1)'], zero_division=0))\n",
    "\n",
    "# --- 5. Save Model & Vectorizer ---\n",
    "\n",
    "joblib.dump(model, 'fake_review_model.joblib')\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "print(\"\\nModel and vectorizer saved successfully!\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
